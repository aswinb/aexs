{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46341ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from easydict import EasyDict\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636bbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.tf2.utils import optimize_linear, compute_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c907640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Model):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = Conv2D(64, 8, strides=(2, 2), activation=\"relu\", padding=\"same\")\n",
    "        self.conv2 = Conv2D(128, 6, strides=(2, 2), activation=\"relu\", padding=\"valid\")\n",
    "        self.conv3 = Conv2D(128, 5, strides=(1, 1), activation=\"relu\", padding=\"valid\")\n",
    "        self.dropout = Dropout(0.25)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(128, activation=\"relu\")\n",
    "        self.dense2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67814f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld_mnist():\n",
    "    \"\"\"Load training and test data.\"\"\"\n",
    "\n",
    "    def convert_types(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255\n",
    "        return image, label\n",
    "\n",
    "    dataset, info = tfds.load(\n",
    "        \"mnist\", data_dir=\"gs://tfds-data/datasets\", with_info=True, as_supervised=True\n",
    "    )\n",
    "    mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]\n",
    "    mnist_train = mnist_train.map(convert_types).shuffle(10000).batch(128)\n",
    "    mnist_test = mnist_test.map(convert_types).batch(128)\n",
    "    return EasyDict(train=mnist_train, test=mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3728f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ld_mnist()\n",
    "model = Net()\n",
    "loss_object = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two sets of loss and performance metrics for the two models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2ba4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss1 = tf.metrics.Mean(name=\"train_loss\")\n",
    "test_acc_clean1 = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_fgsm1 = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_pgd1 = tf.metrics.SparseCategoricalAccuracy()\n",
    "train_loss2 = tf.metrics.Mean(name=\"train_loss\")\n",
    "test_acc_clean2 = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_fgsm2 = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_pgd2 = tf.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efb975c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y):\n",
    "      with tf.GradientTape() as tape:\n",
    "           predictions = model(x)\n",
    "           loss = loss_object(y, predictions)\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "      train_loss1(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aede701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a second model with identical architecture and its training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf0a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57e16035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2_step(x, y):\n",
    "      with tf.GradientTape() as tape:\n",
    "           predictions = model2(x)\n",
    "           loss = loss_object(y, predictions)\n",
    "      gradients = tape.gradient(loss, model2.trainable_variables)\n",
    "      optimizer.apply_gradients(zip(gradients, model2.trainable_variables))\n",
    "      train_loss2(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3244ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 6\n",
    "eps = 0.2\n",
    "adv_train = False\n",
    "loss_fn = tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "targeted=False\n",
    "norm = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training of first model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bbe758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0539\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs):\n",
    "        # keras like display of progress\n",
    "        progress_bar_train = tf.keras.utils.Progbar(60000)\n",
    "        for (x, y) in data.train:            \n",
    "            train_step(x, y)\n",
    "            progress_bar_train.add(x.shape[0], values=[(\"loss\", train_loss.result())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c349606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metrics for first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86ed59b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 26s 3ms/step\n",
      "test acc on clean examples (%): 98.860\n",
      "test acc on FGM adversarial examples (%): 19.020\n"
     ]
    }
   ],
   "source": [
    "progress_bar_test = tf.keras.utils.Progbar(10000)\n",
    "for x, y in data.test:\n",
    "    y_pred = model(x)\n",
    "    test_acc_clean1(y, y_pred)\n",
    "\n",
    "    x_fgm = fast_gradient_method(model, x, eps, np.inf)\n",
    "    y_pred_fgm = model(x_fgm)\n",
    "    test_acc_fgsm1(y, y_pred_fgm)\n",
    "\n",
    "    #x_pgd = projected_gradient_descent(model, x,eps, 0.01, 40, np.inf)\n",
    "    #y_pred_pgd = model(x_pgd)\n",
    "    #test_acc_pgd(y, y_pred_pgd)\n",
    "\n",
    "    progress_bar_test.add(x.shape[0])\n",
    "\n",
    "print(\n",
    "    \"test acc on clean examples (%): {:.3f}\".format(test_acc_clean1.result() * 100)\n",
    ")\n",
    "print(\n",
    "    \"test acc on FGM adversarial examples (%): {:.3f}\".format(\n",
    "        test_acc_fgsm1.result() * 100\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metrics for second model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71be21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 27s 3ms/step\n",
      "test acc on clean examples (%): 8.830\n",
      "test acc on FGM adversarial examples (%): 10.190\n"
     ]
    }
   ],
   "source": [
    "progress_bar_test = tf.keras.utils.Progbar(10000)\n",
    "for x, y in data.test:\n",
    "    y_pred2 = model2(x)\n",
    "    test_acc_clean2(y, y_pred2)\n",
    "\n",
    "    x_fgm = fast_gradient_method(model2, x, eps, np.inf)\n",
    "    y_pred_fgm2 = model2(x_fgm)\n",
    "    test_acc_fgsm2(y, y_pred_fgm2)\n",
    "\n",
    "    #x_pgd = projected_gradient_descent(model, x,eps, 0.01, 40, np.inf)\n",
    "    #y_pred_pgd = model(x_pgd)\n",
    "    #test_acc_pgd(y, y_pred_pgd)\n",
    "\n",
    "    progress_bar_test.add(x.shape[0])\n",
    "\n",
    "print(\n",
    "    \"test acc on clean examples (%): {:.3f}\".format(test_acc_clean2.result() * 100)\n",
    ")\n",
    "print(\n",
    "    \"test acc on FGM adversarial examples (%): {:.3f}\".format(\n",
    "        test_acc_fgsm2.result() * 100\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03f75dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_train = True\n",
    "nb_epochs = 2\n",
    "eps = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter training\n",
    "#train the second model(=model2) with adversarial data from the first model (=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0a9c34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 211s 4ms/step - loss: 0.2345\n",
      "60000/60000 [==============================] - 224s 4ms/step - loss: 0.2189\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs):\n",
    "        # keras like display of progress\n",
    "        progress_bar_train = tf.keras.utils.Progbar(60000)\n",
    "        for (x2, y2) in data.train:\n",
    "            if adv_train:\n",
    "                # Replace clean example with adversarial example for adversarial training\n",
    "                 x2 = fast_gradient_method(model, x2, eps, np.inf)\n",
    "                 y_adv = np.argmax(model(x2),axis=1)\n",
    "                 #print(y_adv.shape)\n",
    "                 #x = projected_gradient_descent(model, x,eps, 0.01, 40, np.inf)\n",
    "            train2_step(x2, y_adv)\n",
    "            progress_bar_train.add(x2.shape[0], values=[(\"loss\", train_loss2.result())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check on the first model again\n",
    "# nothing should have changed after counter training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9455875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 20s 2ms/step\n",
      "test acc on clean examples (%): 98.860\n",
      "test acc on FGM adversarial examples (%): 19.020\n"
     ]
    }
   ],
   "source": [
    "progress_bar_test = tf.keras.utils.Progbar(10000)\n",
    "for x, y in data.test:\n",
    "    y_pred = model(x)\n",
    "    test_acc_clean1(y, y_pred)\n",
    "\n",
    "    x_fgm = fast_gradient_method(model, x, eps, np.inf)\n",
    "    y_pred_fgm = model(x_fgm)\n",
    "    test_acc_fgsm1(y, y_pred_fgm)\n",
    "\n",
    "    #x_pgd = projected_gradient_descent(model, x,eps, 0.01, 40, np.inf)\n",
    "    #y_pred_pgd = model(x_pgd)\n",
    "    #test_acc_pgd(y, y_pred_pgd)\n",
    "\n",
    "    progress_bar_test.add(x.shape[0])\n",
    "\n",
    "print(\n",
    "    \"test acc on clean examples (%): {:.3f}\".format(test_acc_clean1.result() * 100)\n",
    ")\n",
    "print(\n",
    "    \"test acc on FGM adversarial examples (%): {:.3f}\".format(\n",
    "        test_acc_fgsm1.result() * 100\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first model after six epochs of training\n",
    "# test acc on clean examples (%): 98.860\n",
    "# test acc on FGM adversarial examples (%): 19.020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e35115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check on model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "364d4215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s 2ms/step\n",
      "test acc on clean examples (%): 83.396\n",
      "test acc on FGM adversarial examples (%): 7.331\n"
     ]
    }
   ],
   "source": [
    "progress_bar_test = tf.keras.utils.Progbar(10000)\n",
    "for x, y in data.test:\n",
    "    y_pred = model2(x)\n",
    "    test_acc_clean2(y, y_pred)\n",
    "\n",
    "    x_fgm = fast_gradient_method(model2, x, eps, np.inf)\n",
    "    y_pred_fgm = model2(x_fgm)\n",
    "    test_acc_fgsm2(y, y_pred_fgm)\n",
    "\n",
    "    #x_pgd = projected_gradient_descent(model, x,eps, 0.01, 40, np.inf)\n",
    "    #y_pred_pgd = model(x_pgd)\n",
    "    #test_acc_pgd(y, y_pred_pgd)\n",
    "\n",
    "    progress_bar_test.add(x.shape[0])\n",
    "\n",
    "print(\n",
    "    \"test acc on clean examples (%): {:.3f}\".format(test_acc_clean2.result() * 100)\n",
    ")\n",
    "print(\n",
    "    \"test acc on FGM adversarial examples (%): {:.3f}\".format(\n",
    "        test_acc_fgsm2.result() * 100\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b180995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after one round of counter training\n",
    "#test acc on clean examples (%): 51.555\n",
    "#test acc on FGM adversarial examples (%): 6.970\n",
    "\n",
    "#after three rounds of counter training\n",
    "#test acc on clean examples (%): 66.373\n",
    "#test acc on FGM adversarial examples (%): 5.690\n",
    "\n",
    "# after five rounds of counter training \n",
    "#test acc on clean examples (%): 73.842\n",
    "#test acc on FGM adversarial examples (%): 5.340\n",
    "\n",
    "# after six rounds of counter training\n",
    "# test acc on clean examples (%): 78.312\n",
    "# test acc on FGM adversarial examples (%): 5.494\n",
    "\n",
    "# after eight rounds of counter training\n",
    "# test acc on clean examples (%): 81.265\n",
    "# test acc on FGM adversarial examples (%): 6.242\n",
    "\n",
    "# after ten rounds of counter training\n",
    "# test acc on clean examples (%): 83.396\n",
    "# test acc on FGM adversarial examples (%): 7.331"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
